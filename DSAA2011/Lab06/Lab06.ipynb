{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "151072b5",
   "metadata": {},
   "source": [
    "*2025 Spring DSAA 2011 Maching Learning*\n",
    "## Lab Note 06\n",
    "*Weiwen Chen, Guanghua Li, Yifan Zhang, Zixin Zhong* \\\n",
    "*Hong Kong University of Science and Technology (Guangzhou)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da52a7f",
   "metadata": {},
   "source": [
    "**Question 1.** Given a sample $\\mathbf{x}$ and the parameters $(\\boldsymbol{\\theta}, \\theta_0)$, assume the label $y\\in\\{-1, 1\\}$ and \n",
    "$$\n",
    "\\log \\frac{\\operatorname{Pr}\\left(y=1 \\mid \\mathbf{x}, \\boldsymbol{\\theta}, \\theta_0\\right)}{\\operatorname{Pr}\\left(y=-1 \\mid \\mathbf{x}, \\boldsymbol{\\theta}, \\theta_0\\right)}=\\langle\\boldsymbol{\\theta}, \\mathbf{x}\\rangle+\\theta_0.\n",
    "$$\n",
    "Show that\n",
    "$$\n",
    "    \\Pr \\left(y=1 \\mid \\mathbf{x}, \\boldsymbol{\\theta}, \\theta_0\\right)=g\\left(\\langle\\boldsymbol{\\theta}, \\mathbf{x}\\rangle+\\theta_0\\right)=\\frac{1}{1+\\exp \\left(-\\left(\\langle\\boldsymbol{\\theta}, \\mathbf{x}\\rangle+\\theta_0\\right)\\right)}. \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a8d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "207c8b2e",
   "metadata": {},
   "source": [
    "**Question 2.** To find the MLE of parameters for logistic regression, prove the gradients with respect to $\\boldsymbol{\\theta}$ and $\\theta_0$ are as follows:\n",
    "\\begin{align}\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}\\theta_0}\\log \\big[1+\\exp(-y_t( \\langle\\mathbf{x}_t,  \\boldsymbol{\\theta}\\rangle+\\theta_0 ) )\\big]&=  -y_t\\frac{\\exp \\big(-y_t( \\langle\\mathbf{x}_t,  \\boldsymbol{\\theta}\\rangle+\\theta_0 )  \\big)}{1+\\exp \\big(-y_t( \\langle\\mathbf{x}_t,  \\boldsymbol{\\theta}\\rangle+\\theta_0 )  \\big)}  \\\\\n",
    "&=-y_t \\big[ 1-\\Pr(y_t\\mid \\mathbf{x}_t, \\boldsymbol{\\theta}, \\theta_0 ) \\big],\\\\\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}\\boldsymbol{\\theta}}\\log \\big[1+\\exp(-y_t( \\langle\\mathbf{x}_t,  \\boldsymbol{\\theta}\\rangle+\\theta_0 ) )\\big]&=-y_t \\mathbf{x}_t\\big[ 1-\\Pr(y_t\\mid \\mathbf{x}_t, \\boldsymbol{\\theta}, \\theta_0 ) \\big].\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39a3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed4cc4f5",
   "metadata": {},
   "source": [
    "**Question 3.** (i) For $M> 2$ classes, we apply multi-class logistic regression with\n",
    "<!-- \\label{eq:softmax}  -->\n",
    "$$\n",
    "% \\begin{align} \n",
    "\\operatorname{Pr}(y=c \\mid \\mathbf{x} , \\{\\boldsymbol{\\theta}_c , \\theta_{0,c}\\}_{c=1}^M ) = \\frac{\\exp( \\langle \\boldsymbol{\\theta}_c, \\mathbf{x}\\rangle+\\theta_{0,c}  )}{\\sum_{c'=1}^M \\exp(\\langle\\boldsymbol{\\theta}_{c'}, \\mathbf{x}\\rangle+\\theta_{0,c'}  ) } \\\\\n",
    "% \\end{align}\n",
    "$$\n",
    "\n",
    "<!-- \\label{eq:log_reg}  -->\n",
    "(ii) For $M=2$ classes, we apply (binary) logistic regression with\n",
    "\n",
    "$$\n",
    "% \\begin{align} \n",
    "    \\operatorname{Pr} \\left(y=1 \\mid \\mathbf{x}, \\boldsymbol{\\theta}, \\theta_0\\right)\n",
    "    =\\frac{1}{1+\\exp \\left(-\\left(\\langle\\boldsymbol{\\theta}, \\mathbf{x}\\rangle+\\theta_0\\right)\\right)}.\n",
    "% \\end{align}\n",
    "$$\n",
    "**Show** that case (ii) is a special case of case (i).\n",
    "Hint: Without loss of generality, we can assume that one of the classes (say the first one) has $(\\boldsymbol{\\theta}_1, \\theta_{0,1}) =(\\mathbf{0},0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3930d107",
   "metadata": {},
   "source": [
    "**Question 4.** \n",
    "Train and test with a logistic regression model for multi-class classification with a dataset provided in Canvas.\n",
    "\n",
    "For your reference: \n",
    "1. You are recommended to load the dataset following a proper path in your PC. \n",
    "2. Identify features as proper formats, such as numerical or categorical. \n",
    "3. Split the dataset to train set and test set, and train the logistic regression model. \n",
    "4. Test our model and evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd3256f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recommended library:\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "844e3512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age Sex      BP Cholesterol        Na         K   Drug\n",
      "0   23   F    HIGH        HIGH  0.792535  0.031258  drugY\n",
      "1   47   M     LOW        HIGH  0.739309  0.056468  drugC\n",
      "2   47   M     LOW        HIGH  0.697269  0.068944  drugC\n",
      "3   28   F  NORMAL        HIGH  0.563682  0.072289  drugX\n",
      "4   61   F     LOW        HIGH  0.559294  0.030998  drugY\n",
      "0.975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "col_num = ['Age', 'Na', 'K']\n",
    "col_cat = ['Sex', 'BP', 'Cholesterol']\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', StandardScaler(), col_num),('cat', OneHotEncoder(), col_cat)])\n",
    "\n",
    "data = pd.read_csv(\"Drug.csv\")\n",
    "print(data.head())\n",
    "\n",
    "X = data.drop('Drug', axis=1)\n",
    "Y = data['Drug']\n",
    "\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "logisticRegression = LogisticRegression(max_iter=1000)\n",
    "\n",
    "logisticRegression.fit(x_train, y_train)\n",
    "y_pred = logisticRegression.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_true=y_test, y_pred=y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e9fb4",
   "metadata": {},
   "source": [
    "**Question 5.** Train and test with a ridge regression model with the same dataset provided in Question 4. Compare the accuracy and model performance of two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3de28e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "[[ 4  0  0  0  2]\n",
      " [ 0  1  0  0  2]\n",
      " [ 0  0  0  4  1]\n",
      " [ 0  0  0 10  1]\n",
      " [ 0  0  0  0 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         6\n",
      "           1       1.00      0.33      0.50         3\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.71      0.91      0.80        11\n",
      "           4       0.71      1.00      0.83        15\n",
      "\n",
      "    accuracy                           0.75        40\n",
      "   macro avg       0.69      0.58      0.59        40\n",
      "weighted avg       0.69      0.75      0.69        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjr/miniconda3/envs/DSAA2011/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hjr/miniconda3/envs/DSAA2011/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hjr/miniconda3/envs/DSAA2011/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "ridgeClassifier = RidgeClassifier(alpha=1)\n",
    "\n",
    "data = pd.read_csv('Drug.csv')\n",
    "\n",
    "for col in col_cat :\n",
    "\tencoder = LabelEncoder()\n",
    "\tdata[col] = encoder.fit_transform(data[col])\n",
    "\n",
    "X = data[col_num + col_cat]\n",
    "Y = data['Drug']\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(Y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "ridgeClassifier.fit(x_train, y_train)\n",
    "y_pred = ridgeClassifier.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSAA2011",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
